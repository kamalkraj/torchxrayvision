{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from torchxrayvision.models import model_urls, get_weights\n",
    "\n",
    "import huggingface_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful\n",
      "Your token has been saved to /home/kamal_raj/.huggingface/token\n"
     ]
    }
   ],
   "source": [
    "hub.notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of model names to upload to the hub\n",
    "model_names = [\n",
    "    \"densenet121-res224-all\",\n",
    "    \"densenet121-res224-nih\",\n",
    "    \"densenet121-res224-pc\",\n",
    "    \"densenet121-res224-chex\",\n",
    "    \"densenet121-res224-rsna\",\n",
    "    \"densenet121-res224-mimic_nb\",\n",
    "    \"densenet121-res224-mimic_ch\",\n",
    "    \"resnet50-res512-all\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['description', 'weights_url', 'labels', 'op_threshs', 'ppv80_thres'])\n"
     ]
    }
   ],
   "source": [
    "for name in model_names:\n",
    "    print(model_urls[name].keys())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder for storing all model repo\n",
    "local_model_dir = \"hf_models\"\n",
    "os.makedirs(local_model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_and_commit_to_hub(repo, filepath, commit_msg):\n",
    "    \"\"\"\n",
    "    repo: hub.Repository\n",
    "    filepath : file path to add file\n",
    "    commit_msg: commit message for the file\n",
    "    \"\"\"\n",
    "    repo.git_add(os.path.abspath(filepath))\n",
    "    repo.git_commit(commit_message=commit_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_card(model_name, description, repo_name):\n",
    "    # adapted from https://huggingface.co/microsoft/resnet-34/raw/main/README.md\n",
    "    metadata = f\"\"\"\n",
    "---\n",
    "license: apache-2.0\n",
    "tags:\n",
    "- vision\n",
    "- image-classification\n",
    "datasets:\n",
    "- nih-pc-chex-mimic_ch-google-openi-rsna\n",
    "---\n",
    "    \n",
    "    \"\"\"\n",
    "    model_type = \"resnet\" if model_name.startswith(\"resnet\") else \"densenet\"\n",
    "    model_name = f\"# {model_name}\"\n",
    "    if model_type == \"resnet\":\n",
    "        model_info = \"\"\"\n",
    "ResNet (Residual Network) is a convolutional neural network that democratized the concepts of residual learning and skip connections. This enables to train much deeper models.\n",
    "        \"\"\"\n",
    "    else:\n",
    "        model_info = \"\"\"\n",
    "A DenseNet is a type of convolutional neural network that utilises dense connections between layers, through Dense Blocks, where we connect all layers (with matching feature-map sizes) directly with each other. To preserve the feed-forward nature, each layer obtains additional inputs from all preceding layers and passes on its own feature-maps to all subsequent layers.\n",
    "        \"\"\"\n",
    "    if description is not None:\n",
    "        model_info = \"\\n\".join([model_info, description])\n",
    "\n",
    "    how_to_use = f\"\"\"\n",
    "### How to use\n",
    "\n",
    "Here is how to use this model to classify an image of xray:\n",
    "\n",
    "```python\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os,sys\n",
    "sys.path.insert(0,\"..\")\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import skimage, skimage.io\n",
    "import pprint\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision, torchvision.transforms\n",
    "\n",
    "import torchxrayvision as xrv\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-f', type=str, default=\"\", help='')\n",
    "parser.add_argument('img_path', type=str)\n",
    "parser.add_argument('-weights', type=str,default=\"{repo_name}\")\n",
    "parser.add_argument('-feats', default=False, help='', action='store_true')\n",
    "parser.add_argument('-cuda', default=False, help='', action='store_true')\n",
    "parser.add_argument('-resize', default=False, help='', action='store_true')\n",
    "\n",
    "cfg = parser.parse_args()\n",
    "\n",
    "\n",
    "img = skimage.io.imread(cfg.img_path)\n",
    "img = xrv.datasets.normalize(img, 255)  \n",
    "\n",
    "# Check that images are 2D arrays\n",
    "if len(img.shape) > 2:\n",
    "    img = img[:, :, 0]\n",
    "if len(img.shape) < 2:\n",
    "    print(\"error, dimension lower than 2 for image\")\n",
    "\n",
    "# Add color channel\n",
    "img = img[None, :, :]\n",
    "\n",
    "\n",
    "# the models will resize the input to the correct size so this is optional.\n",
    "if cfg.resize:\n",
    "    transform = torchvision.transforms.Compose([xrv.datasets.XRayCenterCrop(),\n",
    "                                                xrv.datasets.XRayResizer(224)])\n",
    "else:\n",
    "    transform = torchvision.transforms.Compose([xrv.datasets.XRayCenterCrop()])\n",
    "\n",
    "img = transform(img)\n",
    "\n",
    "\n",
    "model = xrv.models.get_model(cfg.weights, from_hf_hub=True)\n",
    "\n",
    "output = {{}}\n",
    "with torch.no_grad():\n",
    "    img = torch.from_numpy(img).unsqueeze(0)\n",
    "    if cfg.cuda:\n",
    "        img = img.cuda()\n",
    "        model = model.cuda()\n",
    "        \n",
    "    if cfg.feats:\n",
    "        feats = model.features(img)\n",
    "        feats = F.relu(feats, inplace=True)\n",
    "        feats = F.adaptive_avg_pool2d(feats, (1, 1))\n",
    "        output[\"feats\"] = list(feats.cpu().detach().numpy().reshape(-1))\n",
    "\n",
    "    preds = model(img).cpu()\n",
    "    output[\"preds\"] = dict(zip(xrv.datasets.default_pathologies,preds[0].detach().numpy()))\n",
    "    \n",
    "if cfg.feats:\n",
    "    print(output)\n",
    "else:\n",
    "    pprint.pprint(output)\n",
    "    \n",
    "   \n",
    "```\n",
    "\n",
    "For more code examples, we refer to the [example scripts](https://github.com/kamalkraj/torchxrayvision/blob/master/scripts).\n",
    "\"\"\"\n",
    "\n",
    "    bibtext = \"\"\"\n",
    "### Citation\n",
    "\n",
    "Primary TorchXRayVision paper: [https://arxiv.org/abs/2111.00595](https://arxiv.org/abs/2111.00595)\n",
    "\n",
    "```\n",
    "Joseph Paul Cohen, Joseph D. Viviano, Paul Bertin, Paul Morrison, Parsa Torabian, Matteo Guarrera, Matthew P Lungren, Akshay Chaudhari, Rupert Brooks, Mohammad Hashir, Hadrien Bertrand\n",
    "TorchXRayVision: A library of chest X-ray datasets and models. \n",
    "https://github.com/mlmed/torchxrayvision, 2020\n",
    "\n",
    "\n",
    "@article{Cohen2020xrv,\n",
    "author = {Cohen, Joseph Paul and Viviano, Joseph D. and Bertin, Paul and Morrison, Paul and Torabian, Parsa and Guarrera, Matteo and Lungren, Matthew P and Chaudhari, Akshay and Brooks, Rupert and Hashir, Mohammad and Bertrand, Hadrien},\n",
    "journal = {https://github.com/mlmed/torchxrayvision},\n",
    "title = {{TorchXRayVision: A library of chest X-ray datasets and models}},\n",
    "url = {https://github.com/mlmed/torchxrayvision},\n",
    "year = {2020}\n",
    "arxivId = {2111.00595},\n",
    "}\n",
    "\n",
    "\n",
    "```\n",
    "and this paper which initiated development of the library: [https://arxiv.org/abs/2002.02497](https://arxiv.org/abs/2002.02497)\n",
    "```\n",
    "Joseph Paul Cohen and Mohammad Hashir and Rupert Brooks and Hadrien Bertrand\n",
    "On the limits of cross-domain generalization in automated X-ray prediction. \n",
    "Medical Imaging with Deep Learning 2020 (Online: https://arxiv.org/abs/2002.02497)\n",
    "\n",
    "@inproceedings{cohen2020limits,\n",
    "  title={On the limits of cross-domain generalization in automated X-ray prediction},\n",
    "  author={Cohen, Joseph Paul and Hashir, Mohammad and Brooks, Rupert and Bertrand, Hadrien},\n",
    "  booktitle={Medical Imaging with Deep Learning},\n",
    "  year={2020},\n",
    "  url={https://arxiv.org/abs/2002.02497}\n",
    "}\n",
    "```\n",
    "    \"\"\"\n",
    "    model_card = \"\\n\".join([metadata, model_name, model_info, how_to_use, bibtext])\n",
    "\n",
    "    return model_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "org = \"torchxrayvision\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # delete if repo existing\n",
    "# for name in model_names:\n",
    "#     repo_name = f\"{org}/{name}\"\n",
    "#     hub.delete_repo(repo_id=repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/torchxrayvision/densenet121-res224-all into local empty directory.\n",
      "Several commits (3) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce42afb0cb52444eb62ae519bba55027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file model.pt:   0%|          | 32.0k/27.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/torchxrayvision/densenet121-res224-all\n",
      "   90ee2d6..746c25f  main -> main\n",
      "\n",
      "Cloning https://huggingface.co/torchxrayvision/densenet121-res224-nih into local empty directory.\n",
      "Several commits (3) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6384b1c95457405e91fa68bd2fc02dc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file model.pt:   0%|          | 32.0k/27.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/torchxrayvision/densenet121-res224-nih\n",
      "   e76b9bd..62a4bea  main -> main\n",
      "\n",
      "Cloning https://huggingface.co/torchxrayvision/densenet121-res224-pc into local empty directory.\n",
      "Several commits (3) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaeae8f2f5634816a1fc5aa1eb7d9a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file model.pt:   0%|          | 32.0k/27.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/torchxrayvision/densenet121-res224-pc\n",
      "   80c624b..84f40d1  main -> main\n",
      "\n",
      "Cloning https://huggingface.co/torchxrayvision/densenet121-res224-chex into local empty directory.\n",
      "Several commits (3) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "624be2cef61940c59b1b5d96df37ed5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file model.pt:   0%|          | 32.0k/27.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/torchxrayvision/densenet121-res224-chex\n",
      "   83548db..37cdecd  main -> main\n",
      "\n",
      "Cloning https://huggingface.co/torchxrayvision/densenet121-res224-rsna into local empty directory.\n",
      "Several commits (3) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78e61b4e302a4018a4ff702b02b563b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file model.pt:   0%|          | 32.0k/27.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/torchxrayvision/densenet121-res224-rsna\n",
      "   d99d2cc..0d909bd  main -> main\n",
      "\n",
      "Cloning https://huggingface.co/torchxrayvision/densenet121-res224-mimic_nb into local empty directory.\n",
      "Several commits (3) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae5be491e36466583f3586d3d60d19e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file model.pt:   0%|          | 32.0k/27.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/torchxrayvision/densenet121-res224-mimic_nb\n",
      "   cea5e99..0164ff6  main -> main\n",
      "\n",
      "Cloning https://huggingface.co/torchxrayvision/densenet121-res224-mimic_ch into local empty directory.\n",
      "Several commits (3) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba037a61e90d42e88beb73bd8739f5ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file model.pt:   0%|          | 32.0k/27.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/torchxrayvision/densenet121-res224-mimic_ch\n",
      "   62a3072..b876e76  main -> main\n",
      "\n",
      "Cloning https://huggingface.co/torchxrayvision/resnet50-res512-all into local empty directory.\n",
      "Several commits (3) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01660bff889b470bbb8fefb72279deac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file model.pt:   0%|          | 32.0k/90.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/torchxrayvision/resnet50-res512-all\n",
      "   f532333..911c7ee  main -> main\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# hub\n",
    "for name in model_names:\n",
    "    repo_name = f\"{org}/{name}\"\n",
    "    # create repo\n",
    "    repo_url = hub.create_repo(repo_name, exist_ok=True)\n",
    "    local_repo_dir = f\"{local_model_dir}/{repo_name}\"\n",
    "    repo = hub.Repository(local_dir=local_repo_dir, clone_from=repo_url)\n",
    "    repo.git_pull()\n",
    "    # download weights and move to repo folder\n",
    "    model_path = get_weights(name)\n",
    "    local_model_path = f\"{local_repo_dir}/model.pt\"\n",
    "    shutil.copy(model_path, local_model_path)\n",
    "    add_and_commit_to_hub(repo, local_model_path, \"model file\")\n",
    "    # write labels and other info for model to config.json\n",
    "    model_config = model_urls[name]\n",
    "    description = model_config.pop(\"description\", None)\n",
    "    config_file_path = f\"{local_repo_dir}/config.json\"\n",
    "    with open(config_file_path, \"w\") as f:\n",
    "        json.dump(model_config, f, indent=2)\n",
    "    add_and_commit_to_hub(repo, config_file_path, \"config file\")\n",
    "    # Create model card\n",
    "    model_card_file_path = f\"{local_repo_dir}/README.md\"\n",
    "    with open(model_card_file_path, \"w\") as f:\n",
    "        model_card = get_model_card(name, description, repo_name)\n",
    "        f.write(model_card)\n",
    "    add_and_commit_to_hub(repo, model_card_file_path, \"model card\")\n",
    "    repo.git_push()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "c5a7d17141b8dc7731ff4a3d757083f3581624a76875bd4f3639f28b7aaf413f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
