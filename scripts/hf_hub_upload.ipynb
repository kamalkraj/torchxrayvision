{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from torchxrayvision.models import model_urls, get_weights\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import huggingface_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful\n",
      "Your token has been saved to /home/kamal_raj/.huggingface/token\n"
     ]
    }
   ],
   "source": [
    "hub.notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of model names to upload to the hub\n",
    "model_names = [\n",
    "    \"densenet121-res224-all\",\n",
    "    \"densenet121-res224-nih\",\n",
    "    \"densenet121-res224-pc\",\n",
    "    \"densenet121-res224-chex\",\n",
    "    \"densenet121-res224-rsna\",\n",
    "    \"densenet121-res224-mimic_nb\",\n",
    "    \"densenet121-res224-mimic_ch\",\n",
    "    \"resnet50-res512-all\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['description', 'weights_url', 'labels', 'op_threshs', 'ppv80_thres'])\n"
     ]
    }
   ],
   "source": [
    "for name in model_names:\n",
    "    print(model_urls[name].keys())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder for storing all model repo\n",
    "local_model_dir = \"hf_models\"\n",
    "os.makedirs(local_model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_and_commit_to_hub(repo, filepath, commit_msg):\n",
    "    \"\"\"\n",
    "    repo: hub.Repository\n",
    "    filepath : file path to add file\n",
    "    commit_msg: commit message for the file\n",
    "    \"\"\"\n",
    "    repo.git_add(os.path.abspath(filepath))\n",
    "    repo.git_commit(commit_message=commit_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_card(model_name, description, repo_name):\n",
    "    # adapted from https://huggingface.co/microsoft/resnet-34/raw/main/README.md\n",
    "\n",
    "    ## Add metadata\n",
    "    metadata = f\"\"\"\n",
    "---\n",
    "license: apache-2.0\n",
    "tags:\n",
    "- vision\n",
    "- image-classification\n",
    "datasets:\n",
    "- nih-pc-chex-mimic_ch-google-openi-rsna\n",
    "---\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    ## Add model info\n",
    "    model_type = \"resnet\" if model_name.startswith(\"resnet\") else \"densenet\"\n",
    "    model_name = f\"# {model_name}\"\n",
    "    if model_type == \"resnet\":\n",
    "        model_info = \"\"\"\n",
    "ResNet (Residual Network) is a convolutional neural network that democratized the concepts of residual learning and skip connections. This enables to train much deeper models.\n",
    "        \"\"\"\n",
    "    else:\n",
    "        model_info = \"\"\"\n",
    "A DenseNet is a type of convolutional neural network that utilises dense connections between layers, through Dense Blocks, where we connect all layers (with matching feature-map sizes) directly with each other. To preserve the feed-forward nature, each layer obtains additional inputs from all preceding layers and passes on its own feature-maps to all subsequent layers.\n",
    "        \"\"\"\n",
    "    if description is not None:\n",
    "        model_info = \"\\n\".join([model_info, description])\n",
    "\n",
    "    ## Add model how to use script\n",
    "    how_to_use = f\"\"\"\n",
    "### How to use\n",
    "\n",
    "Here is how to use this model to classify an image of xray:\n",
    "\n",
    "```python\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os,sys\n",
    "sys.path.insert(0,\"..\")\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import skimage, skimage.io\n",
    "import pprint\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision, torchvision.transforms\n",
    "\n",
    "import torchxrayvision as xrv\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-f', type=str, default=\"\", help='')\n",
    "parser.add_argument('img_path', type=str)\n",
    "parser.add_argument('-weights', type=str,default=\"{repo_name}\")\n",
    "parser.add_argument('-feats', default=False, help='', action='store_true')\n",
    "parser.add_argument('-cuda', default=False, help='', action='store_true')\n",
    "parser.add_argument('-resize', default=False, help='', action='store_true')\n",
    "\n",
    "cfg = parser.parse_args()\n",
    "\n",
    "\n",
    "img = skimage.io.imread(cfg.img_path)\n",
    "img = xrv.datasets.normalize(img, 255)  \n",
    "\n",
    "# Check that images are 2D arrays\n",
    "if len(img.shape) > 2:\n",
    "    img = img[:, :, 0]\n",
    "if len(img.shape) < 2:\n",
    "    print(\"error, dimension lower than 2 for image\")\n",
    "\n",
    "# Add color channel\n",
    "img = img[None, :, :]\n",
    "\n",
    "\n",
    "# the models will resize the input to the correct size so this is optional.\n",
    "if cfg.resize:\n",
    "    transform = torchvision.transforms.Compose([xrv.datasets.XRayCenterCrop(),\n",
    "                                                xrv.datasets.XRayResizer(224)])\n",
    "else:\n",
    "    transform = torchvision.transforms.Compose([xrv.datasets.XRayCenterCrop()])\n",
    "\n",
    "img = transform(img)\n",
    "\n",
    "\n",
    "model = xrv.models.get_model(cfg.weights, from_hf_hub=True)\n",
    "\n",
    "output = {{}}\n",
    "with torch.no_grad():\n",
    "    img = torch.from_numpy(img).unsqueeze(0)\n",
    "    if cfg.cuda:\n",
    "        img = img.cuda()\n",
    "        model = model.cuda()\n",
    "        \n",
    "    if cfg.feats:\n",
    "        feats = model.features(img)\n",
    "        feats = F.relu(feats, inplace=True)\n",
    "        feats = F.adaptive_avg_pool2d(feats, (1, 1))\n",
    "        output[\"feats\"] = list(feats.cpu().detach().numpy().reshape(-1))\n",
    "\n",
    "    preds = model(img).cpu()\n",
    "    output[\"preds\"] = dict(zip(xrv.datasets.default_pathologies,preds[0].detach().numpy()))\n",
    "    \n",
    "if cfg.feats:\n",
    "    print(output)\n",
    "else:\n",
    "    pprint.pprint(output)\n",
    "    \n",
    "   \n",
    "```\n",
    "\n",
    "For more code examples, we refer to the [example scripts](https://github.com/kamalkraj/torchxrayvision/blob/master/scripts).\n",
    "\"\"\"\n",
    "\n",
    "    ## Add model and repo Citation info\n",
    "    bibtext = \"\"\"\n",
    "### Citation\n",
    "\n",
    "Primary TorchXRayVision paper: [https://arxiv.org/abs/2111.00595](https://arxiv.org/abs/2111.00595)\n",
    "\n",
    "```\n",
    "Joseph Paul Cohen, Joseph D. Viviano, Paul Bertin, Paul Morrison, Parsa Torabian, Matteo Guarrera, Matthew P Lungren, Akshay Chaudhari, Rupert Brooks, Mohammad Hashir, Hadrien Bertrand\n",
    "TorchXRayVision: A library of chest X-ray datasets and models. \n",
    "https://github.com/mlmed/torchxrayvision, 2020\n",
    "\n",
    "\n",
    "@article{Cohen2020xrv,\n",
    "author = {Cohen, Joseph Paul and Viviano, Joseph D. and Bertin, Paul and Morrison, Paul and Torabian, Parsa and Guarrera, Matteo and Lungren, Matthew P and Chaudhari, Akshay and Brooks, Rupert and Hashir, Mohammad and Bertrand, Hadrien},\n",
    "journal = {https://github.com/mlmed/torchxrayvision},\n",
    "title = {{TorchXRayVision: A library of chest X-ray datasets and models}},\n",
    "url = {https://github.com/mlmed/torchxrayvision},\n",
    "year = {2020}\n",
    "arxivId = {2111.00595},\n",
    "}\n",
    "\n",
    "\n",
    "```\n",
    "and this paper which initiated development of the library: [https://arxiv.org/abs/2002.02497](https://arxiv.org/abs/2002.02497)\n",
    "```\n",
    "Joseph Paul Cohen and Mohammad Hashir and Rupert Brooks and Hadrien Bertrand\n",
    "On the limits of cross-domain generalization in automated X-ray prediction. \n",
    "Medical Imaging with Deep Learning 2020 (Online: https://arxiv.org/abs/2002.02497)\n",
    "\n",
    "@inproceedings{cohen2020limits,\n",
    "  title={On the limits of cross-domain generalization in automated X-ray prediction},\n",
    "  author={Cohen, Joseph Paul and Hashir, Mohammad and Brooks, Rupert and Bertrand, Hadrien},\n",
    "  booktitle={Medical Imaging with Deep Learning},\n",
    "  year={2020},\n",
    "  url={https://arxiv.org/abs/2002.02497}\n",
    "}\n",
    "```\n",
    "    \"\"\"\n",
    "    model_card = \"\\n\".join([metadata, model_name, model_info, how_to_use, bibtext])\n",
    "\n",
    "    return model_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "org = \"torchxrayvision\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete if repo existing\n",
    "# for name in tqdm_notebook(model_names):\n",
    "#     repo_name = f\"{org}/{name}\"\n",
    "#     hub.delete_repo(repo_id=repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22bc8c84a9b443d6af02575de47b86a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/torchxrayvision/densenet121-res224-all into local empty directory.\n",
      "Several commits (3) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4724a70ec4ac4f93b1eb854dd36bfc6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file model.pt:   0%|          | 32.0k/27.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/torchxrayvision/densenet121-res224-all\n",
      "   ae5548c..a7b57f9  main -> main\n",
      "\n",
      "Cloning https://huggingface.co/torchxrayvision/densenet121-res224-nih into local empty directory.\n",
      "Several commits (3) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a9a4b41014404abe6e6b082a506a1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file model.pt:   0%|          | 32.0k/27.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/torchxrayvision/densenet121-res224-nih\n",
      "   34811fb..cd1d7b8  main -> main\n",
      "\n",
      "Cloning https://huggingface.co/torchxrayvision/densenet121-res224-pc into local empty directory.\n",
      "Several commits (3) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b3f6ccb009648f18d1896f23675ae40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file model.pt:   0%|          | 32.0k/27.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/torchxrayvision/densenet121-res224-pc\n",
      "   a5a25d1..ba41241  main -> main\n",
      "\n",
      "Cloning https://huggingface.co/torchxrayvision/densenet121-res224-chex into local empty directory.\n",
      "Several commits (3) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1777af70c2334eae9a40b5c44e0e7ac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file model.pt:   0%|          | 32.0k/27.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/torchxrayvision/densenet121-res224-chex\n",
      "   5309d90..655528d  main -> main\n",
      "\n",
      "Cloning https://huggingface.co/torchxrayvision/densenet121-res224-rsna into local empty directory.\n",
      "Several commits (3) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c43c49bcb37494b9ee6e6e367b51084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file model.pt:   0%|          | 32.0k/27.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/torchxrayvision/densenet121-res224-rsna\n",
      "   7719bc8..3cad3e7  main -> main\n",
      "\n",
      "Cloning https://huggingface.co/torchxrayvision/densenet121-res224-mimic_nb into local empty directory.\n",
      "Several commits (3) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7a353089f754857981414fe7e2bd99f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file model.pt:   0%|          | 32.0k/27.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/torchxrayvision/densenet121-res224-mimic_nb\n",
      "   496ed11..cbfec2b  main -> main\n",
      "\n",
      "Cloning https://huggingface.co/torchxrayvision/densenet121-res224-mimic_ch into local empty directory.\n",
      "Several commits (3) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b0b018f3bdc4a86b5299d3ddc7e7f1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file model.pt:   0%|          | 32.0k/27.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/torchxrayvision/densenet121-res224-mimic_ch\n",
      "   ef18722..0a203b5  main -> main\n",
      "\n",
      "Cloning https://huggingface.co/torchxrayvision/resnet50-res512-all into local empty directory.\n",
      "Several commits (3) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92c4ae0e4f34c1487f01c0de41146f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file model.pt:   0%|          | 32.0k/90.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/torchxrayvision/resnet50-res512-all\n",
      "   5327364..5cec7e0  main -> main\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# hub\n",
    "for name in tqdm_notebook(model_names):\n",
    "    repo_name = f\"{org}/{name}\"\n",
    "    # create repo\n",
    "    repo_url = hub.create_repo(repo_name, exist_ok=True)\n",
    "    local_repo_dir = f\"{local_model_dir}/{repo_name}\"\n",
    "    repo = hub.Repository(local_dir=local_repo_dir, clone_from=repo_url)\n",
    "    repo.git_pull()\n",
    "\n",
    "    # download weights and move to repo folder\n",
    "    model_path = get_weights(name)\n",
    "    local_model_path = f\"{local_repo_dir}/model.pt\"\n",
    "    shutil.copy(model_path, local_model_path)\n",
    "    add_and_commit_to_hub(repo, local_model_path, \"model file\")\n",
    "\n",
    "    # write labels and other info for model to config.json\n",
    "    model_config = model_urls[name]\n",
    "    description = model_config.pop(\"description\", None)\n",
    "    config_file_path = f\"{local_repo_dir}/config.json\"\n",
    "    with open(config_file_path, \"w\") as f:\n",
    "        json.dump(model_config, f, indent=2)\n",
    "    add_and_commit_to_hub(repo, config_file_path, \"config file\")\n",
    "\n",
    "    # Create model card\n",
    "    model_card_file_path = f\"{local_repo_dir}/README.md\"\n",
    "    with open(model_card_file_path, \"w\") as f:\n",
    "        model_card = get_model_card(name, description, repo_name)\n",
    "        f.write(model_card)\n",
    "    add_and_commit_to_hub(repo, model_card_file_path, \"model card\")\n",
    "\n",
    "    # push the files to repo\n",
    "    repo.git_push()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "c5a7d17141b8dc7731ff4a3d757083f3581624a76875bd4f3639f28b7aaf413f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
